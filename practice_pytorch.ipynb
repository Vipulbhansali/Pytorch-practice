{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size (sq ft)\tPrice (thousands of $)\n",
    "650\t                70\n",
    "785\t                95\n",
    "1200\t            130\n",
    "1500\t            200\n",
    "1850\t            230\n",
    "2400\t            300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([650,785,1200,1500,1850,2400,2800,3000,3200,3200,3400,3600]).unsqueeze(1) \n",
    "y = torch.Tensor([70,95,130,200,230,300,340,280, 400,420,500,550]).unsqueeze(1) \n",
    "\n",
    "train_split= int(len(x)*0.8)\n",
    "\n",
    "x_train = x[:train_split]\n",
    "\n",
    "x_test = x[train_split:]    \n",
    "\n",
    "y_train = y[:train_split]   \n",
    "\n",
    "y_test = y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "\n",
    "scaler1.fit(x_train)\n",
    "scaler2.fit(y_train)\n",
    "\n",
    "x_train = torch.tensor(scaler1.transform(x_train), dtype=torch.float32)\n",
    "x_test = torch.tensor(scaler1.transform(x_test), dtype=torch.float32)\n",
    "y_train = torch.tensor(scaler2.transform(y_train), dtype=torch.float32)\n",
    "y_test = torch.tensor(scaler2.transform(y_test), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class linear(nn.Module):\n",
    "    \n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad = True,dtype = torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad = True,dtype = torch.float))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.weights * x + self.bias\n",
    "\n",
    "model = linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([-0.6417])), ('bias', tensor([-0.4442]))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Test Loss: 15.405658721923828 | Loss: 2.847578287124634\n",
      "Epoch: 10 | Test Loss: 11.411028861999512 | Loss: 1.9238660335540771\n",
      "Epoch: 20 | Test Loss: 8.593353271484375 | Loss: 1.307188868522644\n",
      "Epoch: 30 | Test Loss: 6.589013576507568 | Loss: 0.8954901099205017\n",
      "Epoch: 40 | Test Loss: 5.150204658508301 | Loss: 0.6206367015838623\n",
      "Epoch: 50 | Test Loss: 4.107370376586914 | Loss: 0.4371424615383148\n",
      "Epoch: 60 | Test Loss: 3.3439419269561768 | Loss: 0.3146401047706604\n",
      "Epoch: 70 | Test Loss: 2.779343843460083 | Loss: 0.2328566461801529\n",
      "Epoch: 80 | Test Loss: 2.357534170150757 | Loss: 0.17825736105442047\n",
      "Epoch: 90 | Test Loss: 2.0392608642578125 | Loss: 0.14180637896060944\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01,)\n",
    "\n",
    "\n",
    "epoch = 100\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    model.train()\n",
    "    #forward pass\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    #calculate the loss function\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        test_pred = model(x_test)\n",
    "        test_loss = loss_function(test_pred, y_test)  # Use a different variable to avoid confusion\n",
    "\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Epoch: {i} | Test Loss: {test_loss.item()} | Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price for a house with size 2000 sq ft: 227 thousands of dollars\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "new_input = torch.tensor([[2000]], dtype=torch.float32)\n",
    "\n",
    "new_input_n = torch.tensor(scaler1.transform(new_input),dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "\n",
    "    y_pred_n = model(new_input_n)\n",
    "\n",
    "predicted_price = scaler2.inverse_transform(y_pred_n.detach().numpy())\n",
    "rounded_predicted_price = round(predicted_price[0][0])\n",
    "\n",
    "print(f\"Predicted price for a house with size 2000 sq ft: {rounded_predicted_price} thousands of dollars\")\n",
    "                         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2971.2649], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(2000)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([1.4862])), ('bias', tensor([-1.0791]))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
