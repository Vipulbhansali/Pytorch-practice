{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size (sq ft)\tPrice (thousands of $)\n",
    "650\t                70\n",
    "785\t                95\n",
    "1200\t            130\n",
    "1500\t            200\n",
    "1850\t            230\n",
    "2400\t            300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([650,785,1200,1500,1850,2400,2800,3000,3200,3200,3400,3600]).unsqueeze(1) \n",
    "y = torch.Tensor([70,95,130,200,230,300,340,280, 400,420,500,550]).unsqueeze(1) \n",
    "\n",
    "train_split= int(len(x)*0.8)\n",
    "\n",
    "x_train = x[:train_split]\n",
    "\n",
    "x_test = x[train_split:]    \n",
    "\n",
    "y_train = y[:train_split]   \n",
    "\n",
    "y_test = y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "\n",
    "scaler1.fit(x_train)\n",
    "scaler2.fit(y_train)\n",
    "\n",
    "x_train = torch.tensor(scaler1.transform(x_train), dtype=torch.float32)\n",
    "x_test = torch.tensor(scaler1.transform(x_test), dtype=torch.float32)\n",
    "y_train = torch.tensor(scaler2.transform(y_train), dtype=torch.float32)\n",
    "y_test = torch.tensor(scaler2.transform(y_test), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class linear(nn.Module):\n",
    "    \n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad = True,dtype = torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad = True,dtype = torch.float))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.weights * x + self.bias\n",
    "\n",
    "model = linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([-0.6417])), ('bias', tensor([-0.4442]))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Test Loss: 15.405658721923828 | Loss: 2.847578287124634\n",
      "Epoch: 10 | Test Loss: 11.411028861999512 | Loss: 1.9238660335540771\n",
      "Epoch: 20 | Test Loss: 8.593353271484375 | Loss: 1.307188868522644\n",
      "Epoch: 30 | Test Loss: 6.589013576507568 | Loss: 0.8954901099205017\n",
      "Epoch: 40 | Test Loss: 5.150204658508301 | Loss: 0.6206367015838623\n",
      "Epoch: 50 | Test Loss: 4.107370376586914 | Loss: 0.4371424615383148\n",
      "Epoch: 60 | Test Loss: 3.3439419269561768 | Loss: 0.3146401047706604\n",
      "Epoch: 70 | Test Loss: 2.779343843460083 | Loss: 0.2328566461801529\n",
      "Epoch: 80 | Test Loss: 2.357534170150757 | Loss: 0.17825736105442047\n",
      "Epoch: 90 | Test Loss: 2.0392608642578125 | Loss: 0.14180637896060944\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01,)\n",
    "\n",
    "\n",
    "epoch = 100\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    model.train()\n",
    "    #forward pass\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    #calculate the loss function\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        test_pred = model(x_test)\n",
    "        test_loss = loss_function(test_pred, y_test)  # Use a different variable to avoid confusion\n",
    "\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Epoch: {i} | Test Loss: {test_loss.item()} | Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price for a house with size 2000 sq ft: 227 thousands of dollars\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "new_input = torch.tensor([[2000]], dtype=torch.float32)\n",
    "\n",
    "new_input_n = torch.tensor(scaler1.transform(new_input),dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "\n",
    "    y_pred_n = model(new_input_n)\n",
    "\n",
    "predicted_price = scaler2.inverse_transform(y_pred_n.detach().numpy())\n",
    "rounded_predicted_price = round(predicted_price[0][0])\n",
    "\n",
    "print(f\"Predicted price for a house with size 2000 sq ft: {rounded_predicted_price} thousands of dollars\")\n",
    "                         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2971.2649], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(2000)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([1.4862])), ('bias', tensor([-1.0791]))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "X = torch.from_numpy(X).type(torch.float) \n",
    "y=torch.from_numpy(y).type(torch.float).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6010,  1.5354],\n",
       "         [ 0.7559, -1.1724],\n",
       "         [ 1.3545, -0.9485],\n",
       "         ...,\n",
       "         [ 2.8443,  0.2113],\n",
       "         [-0.0259,  1.6193],\n",
       "         [ 3.6415,  0.7569]]),\n",
       " tensor([[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sample in the dataset (input, target):\n",
      "(tensor([0.6010, 1.5354]), tensor([1.]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# Print a sample from the dataset to verify\n",
    "print(\"First sample in the dataset (input, target):\")\n",
    "print(dataset[0])\n",
    "\n",
    "# Define the size of the train and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size  # 20% for validation\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for each subset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "class classification(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(in_features =2, out_features =5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(in_features =5, out_features =5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(in_features =5, out_features =1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "       # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.kaiming_uniform_(self.layer1.weight, nonlinearity='relu')\n",
    "        init.kaiming_uniform_(self.layer2.weight, nonlinearity='relu')\n",
    "        init.xavier_uniform_(self.layer3.weight)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = classification()\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Test Loss: 4.93992292881012 |Loss :0.6097389459609985\n",
      "Epoch: 10 | Test Loss: 4.526598036289215 |Loss :0.6433552503585815\n",
      "Epoch: 20 | Test Loss: 4.210879594087601 |Loss :0.6570175290107727\n",
      "Epoch: 30 | Test Loss: 3.9151229560375214 |Loss :0.6556727886199951\n",
      "Epoch: 40 | Test Loss: 3.624013662338257 |Loss :0.43930700421333313\n",
      "Epoch: 50 | Test Loss: 3.373994380235672 |Loss :0.3710995316505432\n",
      "Epoch: 60 | Test Loss: 3.1601013839244843 |Loss :0.4291967749595642\n",
      "Epoch: 70 | Test Loss: 2.9737463295459747 |Loss :0.4223328232765198\n",
      "Epoch: 80 | Test Loss: 2.809806853532791 |Loss :0.36991798877716064\n",
      "Epoch: 90 | Test Loss: 2.6676687002182007 |Loss :0.3254834711551666\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        y_pred = model(x_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        total_test_loss = 0\n",
    "        for x_batch_test,y_batch_test in val_loader:\n",
    "            y_pred_test = model(x_batch_test)\n",
    "            loss_test = loss_fn(y_pred_test, y_batch_test)\n",
    "            total_test_loss += loss_test.item()\n",
    "\n",
    "    if i % 10 == 0:  \n",
    "        \n",
    "        print(f\"Epoch: {i} | Test Loss: {total_test_loss} |Loss :{loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[-1.1517, -1.0421],\n",
       "                      [ 0.7741,  1.0733],\n",
       "                      [-1.3224, -1.4856],\n",
       "                      [-1.2364, -1.7339],\n",
       "                      [ 1.2889, -1.4183]])),\n",
       "             ('layer1.bias',\n",
       "              tensor([-0.2886,  0.3063,  0.3707, -0.2545, -0.3641])),\n",
       "             ('layer2.weight',\n",
       "              tensor([[-1.0165,  0.5927,  0.0496,  0.3243, -0.5718],\n",
       "                      [-1.0418,  0.8909, -0.2275, -0.7642, -0.2403],\n",
       "                      [-0.3754, -0.2449,  1.0338, -0.1188,  0.1385],\n",
       "                      [-0.5173,  0.7788, -0.9623, -0.5964, -0.1182],\n",
       "                      [ 0.9511,  0.1484,  0.2846, -1.0204,  0.4142]])),\n",
       "             ('layer2.bias',\n",
       "              tensor([ 0.2465, -0.2832,  0.7252, -0.1924, -0.5247])),\n",
       "             ('layer3.weight',\n",
       "              tensor([[ 1.1338, -0.0162, -0.4390,  0.5082,  0.1538]])),\n",
       "             ('layer3.bias', tensor([-0.2043]))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
